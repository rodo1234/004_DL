{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodo/code/proyecto_4/004_DL/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-04-02 19:04:45.993222: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-02 19:04:45.993470: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 19:04:45.995390: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-02 19:04:46.019603: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-02 19:04:46.559604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingStrategyOptimizer:\n",
    "    def __init__(self, buy_data_path, sell_data_path):\n",
    "        self.buy_data_path = buy_data_path\n",
    "        self.sell_data_path = sell_data_path\n",
    "        \n",
    "    \n",
    "    def load_and_preprocess_data(self, path):\n",
    "        data = pd.read_csv(path)\n",
    "        y = data.pop('Y_BUY' if 'buy' in path else 'Y_SELL').values\n",
    "        X = data.values\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        return train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    def objective(self, trial, X_train, y_train, X_val, y_val):\n",
    "        n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "        n_units = trial.suggest_int('n_units', 50, 200)\n",
    "        lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(n_units, input_dim=X_train.shape[1], activation='relu'))\n",
    "        for _ in range(n_layers - 1):\n",
    "            model.add(tf.keras.layers.Dense(n_units, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n",
    "                      loss='binary_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, verbose=False)\n",
    "        _, accuracy = model.evaluate(X_val, y_val, verbose=False)\n",
    "        return accuracy\n",
    "    \n",
    "    def optimize_dnn(self, X_train, y_train, X_val, y_val):\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        func = lambda trial: self.objective(trial, X_train, y_train, X_val, y_val)\n",
    "        study.optimize(func, n_trials=5)\n",
    "        return study.best_trial.params\n",
    "\n",
    "    def build_and_train_model(self, best_params, X_train, y_train):\n",
    "        n_layers = best_params['n_layers']\n",
    "        n_units = best_params['n_units']\n",
    "        lr = best_params['lr']\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(n_units, input_dim=X_train.shape[1], activation='relu'))\n",
    "        for _ in range(n_layers - 1):\n",
    "            model.add(tf.keras.layers.Dense(n_units, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n",
    "                      loss='binary_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        model.fit(X_train, y_train, epochs=5, verbose=False)\n",
    "        return model\n",
    "    \n",
    "    # create a dataframe with the Y_buy and Y_sell columns predicted\n",
    "    def run(self):\n",
    "        X_train_buy, X_val_buy, y_train_buy, y_val_buy = self.load_and_preprocess_data(self.buy_data_path)\n",
    "        X_train_sell, X_val_sell, y_train_sell, y_val_sell = self.load_and_preprocess_data(self.sell_data_path)\n",
    "        \n",
    "        best_params_buy = self.optimize_dnn(X_train_buy, y_train_buy, X_val_buy, y_val_buy)\n",
    "        best_params_sell = self.optimize_dnn(X_train_sell, y_train_sell, X_val_sell, y_val_sell)\n",
    "        \n",
    "        model_buy = self.build_and_train_model(best_params_buy, X_train_buy, y_train_buy)\n",
    "        model_sell = self.build_and_train_model(best_params_sell, X_train_sell, y_train_sell)\n",
    "        \n",
    "        y_pred_buy = model_buy.predict(X_val_buy)\n",
    "        y_pred_sell = model_sell.predict(X_val_sell)\n",
    "        \n",
    "        # covertir a booleanos\n",
    "        y_pred_buy = y_pred_buy > 0.5\n",
    "        y_pred_sell = y_pred_sell > 0.5\n",
    "        \n",
    "        \n",
    "        return pd.DataFrame({'Y_BUY_PRED': y_pred_buy.flatten(), 'Y_SELL_PRED': y_pred_sell.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-02 19:04:47,021] A new study created in memory with name: no-name-19724f0a-0fea-4f72-8250-f8230c32736a\n",
      "/tmp/ipykernel_31072/2717340414.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-4, 1e-2)\n",
      "/home/rodo/code/proyecto_4/004_DL/.venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-04-02 19:04:48.674392: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-02 19:04:48.674644: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "[I 2024-04-02 19:04:57,271] Trial 0 finished with value: 0.5122660398483276 and parameters: {'n_layers': 3, 'n_units': 60, 'lr': 0.0001632903324661195}. Best is trial 0 with value: 0.5122660398483276.\n",
      "[I 2024-04-02 19:05:06,295] Trial 1 finished with value: 0.5116338133811951 and parameters: {'n_layers': 3, 'n_units': 117, 'lr': 0.00012944137390269607}. Best is trial 0 with value: 0.5122660398483276.\n",
      "[I 2024-04-02 19:05:15,004] Trial 2 finished with value: 0.5130248069763184 and parameters: {'n_layers': 3, 'n_units': 94, 'lr': 0.00012880359802236324}. Best is trial 2 with value: 0.5130248069763184.\n",
      "[I 2024-04-02 19:05:24,319] Trial 3 finished with value: 0.5087253451347351 and parameters: {'n_layers': 2, 'n_units': 188, 'lr': 0.0002449118424406284}. Best is trial 2 with value: 0.5130248069763184.\n",
      "[I 2024-04-02 19:05:32,941] Trial 4 finished with value: 0.4970915615558624 and parameters: {'n_layers': 2, 'n_units': 166, 'lr': 0.008981836408655424}. Best is trial 2 with value: 0.5130248069763184.\n",
      "[I 2024-04-02 19:05:32,942] A new study created in memory with name: no-name-a5ecdacb-2df7-4025-95cd-52e0bcf1cd02\n",
      "[I 2024-04-02 19:05:41,985] Trial 0 finished with value: 0.5151745080947876 and parameters: {'n_layers': 2, 'n_units': 114, 'lr': 0.00041042789839794246}. Best is trial 0 with value: 0.5151745080947876.\n",
      "[I 2024-04-02 19:05:50,639] Trial 1 finished with value: 0.5144158005714417 and parameters: {'n_layers': 3, 'n_units': 86, 'lr': 0.000508905418634598}. Best is trial 0 with value: 0.5151745080947876.\n",
      "[I 2024-04-02 19:05:57,898] Trial 2 finished with value: 0.5136570334434509 and parameters: {'n_layers': 1, 'n_units': 87, 'lr': 0.0040642668061885295}. Best is trial 0 with value: 0.5151745080947876.\n",
      "[I 2024-04-02 19:06:06,860] Trial 3 finished with value: 0.515553891658783 and parameters: {'n_layers': 2, 'n_units': 198, 'lr': 0.00017531907841718955}. Best is trial 3 with value: 0.515553891658783.\n",
      "[I 2024-04-02 19:06:14,130] Trial 4 finished with value: 0.5158067941665649 and parameters: {'n_layers': 1, 'n_units': 100, 'lr': 0.00029334527282112195}. Best is trial 4 with value: 0.5158067941665649.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step\n",
      "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step\n",
      "      Y_BUY_PRED  Y_SELL_PRED\n",
      "0          False         True\n",
      "1           True         True\n",
      "2           True        False\n",
      "3           True         True\n",
      "4           True         True\n",
      "...          ...          ...\n",
      "7903        True        False\n",
      "7904        True        False\n",
      "7905        True         True\n",
      "7906        True        False\n",
      "7907        True        False\n",
      "\n",
      "[7908 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    optimizer = TradingStrategyOptimizer('/home/rodo/code/proyecto_4/004_DL/data/close_data_buy_5.csv', '/home/rodo/code/proyecto_4/004_DL/data/close_data_sell_5.csv')\n",
    "    df = optimizer.run()\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
